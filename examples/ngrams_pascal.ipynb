{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Generating random words from NGrams\n","From \n","\n","- https://github.com/josh-freeman/HPshape/blob/main/examples/Word%20generation%20with%20N-Grams%20(Solution).ipynb\n","- https://github.com/josh-freeman/HPshape/blob/main/examples/ngrams.ipynb  "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in c:\\users\\jfreeman\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.64.0)\n","Requirement already satisfied: colorama in c:\\users\\jfreeman\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm) (0.4.5)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.3.1 -> 23.0.1\n","[notice] To update, run: C:\\Users\\jfreeman\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]}],"source":["#!/usr/bin/env python3\n","!pip install tqdm \n","# for the impatients...\n","import numpy as np\n","import itertools"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package words to\n","[nltk_data]     C:\\Users\\jfreeman\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]}],"source":["import nltk\n","words = nltk.download('words')\n","from nltk.corpus import words"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Core Model"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class NGram ():\n","    \n","    end_token = '\\x00'\n","    \n","    \n","    def __init__(self,n=3):\n","        \n","        alphabet  = [c for c in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ-\"]\n","        alphabet.append(self.end_token)\n","        all_words = np.array([x for x in words.words() if len(x) >= 2])\n","        np.random.shuffle(all_words)\n","        \n","        self.n = n\n","        self.alphabet = alphabet\n","        self.words = all_words\n","        self.n_characters = np.array([np.array(p) for p in itertools.product(alphabet, repeat = n)])\n","        \n","        self.combinations  =  np.array([np.array(p) for p in itertools.product(alphabet, repeat = n + 1)])\n","        self.counters      =  np.zeros((self.combinations.shape[0]), dtype=np.int64)\n","        self.probabilities =  None\n","        \n","    def update(self,n1,n2):\n","        from tqdm import tqdm\n","        n = self.n\n","        counters = self.counters\n","        combins  = self.combinations\n","        words    = self.words[n1:n2]\n","        end_tok  = self.end_token\n","        \n","        for w in tqdm(words):\n","            t = formatting(w,n,end_tok)\n","            for i in range(n, len(t)):\n","                gram = np.array(t[i-n:i+1])\n","                index = find_index(combins, gram)\n","                counters[index] += 1\n","                \n","    def compute_probabilities(self):\n","        \n","        probabilities = self.counters.reshape((len(self.n_characters), len(self.alphabet)))\n","        sum_probs     = probabilities.sum(axis=1, keepdims=True)\n","        \n","        #probabilities = np.nan_to_num(probabilities / , 0)\n","        \n","        self.probabilities = np.divide(probabilities,sum_probs,where=(sum_probs>0))\n","                \n","    def generate(self):\n","       end_token = self.end_token\n","       n         = self.n\n","       result = [end_token]*n\n","       while True:\n","           index  = find_index(self.n_characters, result[-n:])\n","           choice = np.random.choice(self.alphabet,p=fix_p(self.probabilities[index]))\n","           result.append(choice)\n","           if choice == np.array(end_token):\n","                    break\n","        \n","       return \"\".join(result)\n","   \n","    \n","    def probability (self,word):\n","       \n","       return(multi_probability(self.counters,self.combinations,word,self.n,self.end_token))\n","   \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Utilities"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def formatting(w,n,end_token):\n","    return [end_token]*n + tokenizer(w) + [end_token]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def single_probability(counters,combinations,c, gram): \n","    gram_plus_c = counters[find_index(combinations, np.array(list(gram) + [c]))]\n","    gram_total = np.sum(counters)\n","    \n","    if gram_total == 0:\n","        return 0\n","    else:\n","        return gram_plus_c / gram_total\n","    \n","def multi_probability(counters,combinations,w:str,n,end_token):\n","    \n","    probability = 1\n","    formatted = formatting(w,n,end_token)\n","    for i in range(n, len(formatted)-1): \n","        c = formatted[i]\n","        gram = np.array(formatted[i-n:i])\n","        probability *= single_probability(counters,combinations,c,gram)\n","    return probability    "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def fix_p(p):\n","     if p.sum() == 0:\n","         p = np.ones((len(p))) / len(p)\n","     elif p.sum() != 1.0:\n","         p = p*(1./p.sum())\n","     return p"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def asvoid(arr):\n","    arr = np.ascontiguousarray(arr)\n","    return arr.view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[-1])))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def find_index(arr, x):\n","    arr_as1d = asvoid(arr)\n","    x = asvoid(x)\n","    return np.nonzero(arr_as1d == x)[0][0]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":[" 10%|â–‰         | 198/2000 [04:47<48:38,  1.62s/it] "]}],"source":["def tokenizer(s:str):\n","    l = [c for c in s] \n","    return l\n","\n","N = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n","ngram = NGram(N)\n","\n","UPDATE_FROM = 0\n","UPDATE_TO = 2000 #@param {type:\"slider\", min:1, max:5000, step:1}\n","ngram.update(UPDATE_FROM,UPDATE_TO)\n","\n","ngram.compute_probabilities()\n","\n","WORDS_TO_GENERATE = 20 #@param {type:\"slider\", min:1, max:3072, step:1}\n","for i in range(WORDS_TO_GENERATE): print(ngram.generate())"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":2}
